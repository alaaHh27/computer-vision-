{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e0cf413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import cv2\n",
    "from PIL import Image, ImageTk\n",
    "import customtkinter as ctk\n",
    "from tkinter import filedialog\n",
    "from IPython import get_ipython\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "840336ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Classes: ['Apple Braeburn', 'Apple Crimson Snow', 'Apple Golden 1', 'Apple Golden 2', 'Apple Golden 3', 'Apple Granny Smith', 'Apple Pink Lady', 'Apple Red 1', 'Apple Red 2', 'Apple Red 3', 'Apple Red Delicious', 'Apple Red Yellow 1', 'Apple Red Yellow 2', 'Apricot', 'Avocado', 'Avocado ripe', 'Banana', 'Banana Lady Finger', 'Banana Red', 'Beetroot', 'Blueberry', 'Cactus fruit', 'Cantaloupe 1', 'Cantaloupe 2', 'Carambula', 'Cauliflower', 'Cherry 1', 'Cherry 2', 'Cherry Rainier', 'Cherry Wax Black', 'Cherry Wax Red', 'Cherry Wax Yellow', 'Chestnut', 'Clementine', 'Cocos', 'Corn', 'Corn Husk', 'Cucumber Ripe', 'Cucumber Ripe 2', 'Dates', 'Eggplant', 'Fig', 'Ginger Root', 'Granadilla', 'Grape Blue', 'Grape Pink', 'Grape White', 'Grape White 2', 'Grape White 3', 'Grape White 4', 'Grapefruit Pink', 'Grapefruit White', 'Guava', 'Hazelnut', 'Huckleberry', 'Kaki', 'Kiwi', 'Kohlrabi', 'Kumquats', 'Lemon', 'Lemon Meyer', 'Limes', 'Lychee', 'Mandarine', 'Mango', 'Mango Red', 'Mangostan', 'Maracuja', 'Melon Piel de Sapo', 'Mulberry', 'Nectarine', 'Nectarine Flat', 'Nut Forest', 'Nut Pecan', 'Onion Red', 'Onion Red Peeled', 'Onion White', 'Orange', 'Papaya', 'Passion Fruit', 'Peach', 'Peach 2', 'Peach Flat', 'Pear', 'Pear 2', 'Pear Abate', 'Pear Forelle', 'Pear Kaiser', 'Pear Monster', 'Pear Red', 'Pear Stone', 'Pear Williams', 'Pepino', 'Pepper Green', 'Pepper Orange', 'Pepper Red', 'Pepper Yellow', 'Physalis', 'Physalis with Husk', 'Pineapple', 'Pineapple Mini', 'Pitahaya Red', 'Plum', 'Plum 2', 'Plum 3', 'Pomegranate', 'Pomelo Sweetie', 'Potato Red', 'Potato Red Washed', 'Potato Sweet', 'Potato White', 'Quince', 'Rambutan', 'Raspberry', 'Redcurrant', 'Salak', 'Strawberry', 'Strawberry Wedge', 'Tamarillo', 'Tangelo', 'Tomato 1', 'Tomato 2', 'Tomato 3', 'Tomato 4', 'Tomato Cherry Red', 'Tomato Heart', 'Tomato Maroon', 'Tomato Yellow', 'Tomato not Ripened', 'Walnut', 'Watermelon']\n",
      "Using classes: ['Apple Braeburn', 'Apple Crimson Snow', 'Apple Golden 1', 'Apple Golden 2', 'Apple Golden 3', 'Apple Granny Smith', 'Apple Pink Lady', 'Apple Red 1', 'Apple Red 2', 'Apple Red 3', 'Apple Red Delicious', 'Apple Red Yellow 1', 'Apple Red Yellow 2', 'Apricot', 'Avocado', 'Avocado ripe', 'Banana', 'Banana Lady Finger', 'Banana Red', 'Beetroot', 'Blueberry']\n"
     ]
    }
   ],
   "source": [
    "root_dir = 'E:\\computer Vision\\project\\master\\Fruit-Images-Dataset-master'\n",
    "train_dir = \"E:\\computer Vision\\project\\master\\Fruit-Images-Dataset-master\\Training\"\n",
    "test_dir = \"E:\\computer Vision\\project\\master\\Fruit-Images-Dataset-master\\Test\"\n",
    "\n",
    "class_names = sorted(os.listdir(train_dir))\n",
    "print(\"All Classes:\", class_names)\n",
    "\n",
    "selected_classes = class_names[:21] \n",
    "\n",
    "print(\"Using classes:\", selected_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cdd3e854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training images: 67692\n",
      "Total testing images: 22688\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_files = []\n",
    "for cls in class_names:\n",
    "    train_files += glob(os.path.join(train_dir, cls, \"*.jpg\"))\n",
    "\n",
    "\n",
    "test_files = []\n",
    "for cls in class_names:\n",
    "    test_files += glob(os.path.join(test_dir, cls, \"*.jpg\"))\n",
    "\n",
    "print(f\"Total training images: {len(train_files)}\")\n",
    "print(f\"Total testing images: {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c229fe73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Classes: 131\n",
      "1. Apple Braeburn\n",
      "2. Apple Crimson Snow\n",
      "3. Apple Golden 1\n",
      "4. Apple Golden 2\n",
      "5. Apple Golden 3\n",
      "6. Apple Granny Smith\n",
      "7. Apple Pink Lady\n",
      "8. Apple Red 1\n",
      "9. Apple Red 2\n",
      "10. Apple Red 3\n",
      "11. Apple Red Delicious\n",
      "12. Apple Red Yellow 1\n",
      "13. Apple Red Yellow 2\n",
      "14. Apricot\n",
      "15. Avocado\n",
      "16. Avocado ripe\n",
      "17. Banana\n",
      "18. Banana Lady Finger\n",
      "19. Banana Red\n",
      "20. Beetroot\n",
      "21. Blueberry\n",
      "22. Cactus fruit\n",
      "23. Cantaloupe 1\n",
      "24. Cantaloupe 2\n",
      "25. Carambula\n",
      "26. Cauliflower\n",
      "27. Cherry 1\n",
      "28. Cherry 2\n",
      "29. Cherry Rainier\n",
      "30. Cherry Wax Black\n",
      "31. Cherry Wax Red\n",
      "32. Cherry Wax Yellow\n",
      "33. Chestnut\n",
      "34. Clementine\n",
      "35. Cocos\n",
      "36. Corn\n",
      "37. Corn Husk\n",
      "38. Cucumber Ripe\n",
      "39. Cucumber Ripe 2\n",
      "40. Dates\n",
      "41. Eggplant\n",
      "42. Fig\n",
      "43. Ginger Root\n",
      "44. Granadilla\n",
      "45. Grape Blue\n",
      "46. Grape Pink\n",
      "47. Grape White\n",
      "48. Grape White 2\n",
      "49. Grape White 3\n",
      "50. Grape White 4\n",
      "51. Grapefruit Pink\n",
      "52. Grapefruit White\n",
      "53. Guava\n",
      "54. Hazelnut\n",
      "55. Huckleberry\n",
      "56. Kaki\n",
      "57. Kiwi\n",
      "58. Kohlrabi\n",
      "59. Kumquats\n",
      "60. Lemon\n",
      "61. Lemon Meyer\n",
      "62. Limes\n",
      "63. Lychee\n",
      "64. Mandarine\n",
      "65. Mango\n",
      "66. Mango Red\n",
      "67. Mangostan\n",
      "68. Maracuja\n",
      "69. Melon Piel de Sapo\n",
      "70. Mulberry\n",
      "71. Nectarine\n",
      "72. Nectarine Flat\n",
      "73. Nut Forest\n",
      "74. Nut Pecan\n",
      "75. Onion Red\n",
      "76. Onion Red Peeled\n",
      "77. Onion White\n",
      "78. Orange\n",
      "79. Papaya\n",
      "80. Passion Fruit\n",
      "81. Peach\n",
      "82. Peach 2\n",
      "83. Peach Flat\n",
      "84. Pear\n",
      "85. Pear 2\n",
      "86. Pear Abate\n",
      "87. Pear Forelle\n",
      "88. Pear Kaiser\n",
      "89. Pear Monster\n",
      "90. Pear Red\n",
      "91. Pear Stone\n",
      "92. Pear Williams\n",
      "93. Pepino\n",
      "94. Pepper Green\n",
      "95. Pepper Orange\n",
      "96. Pepper Red\n",
      "97. Pepper Yellow\n",
      "98. Physalis\n",
      "99. Physalis with Husk\n",
      "100. Pineapple\n",
      "101. Pineapple Mini\n",
      "102. Pitahaya Red\n",
      "103. Plum\n",
      "104. Plum 2\n",
      "105. Plum 3\n",
      "106. Pomegranate\n",
      "107. Pomelo Sweetie\n",
      "108. Potato Red\n",
      "109. Potato Red Washed\n",
      "110. Potato Sweet\n",
      "111. Potato White\n",
      "112. Quince\n",
      "113. Rambutan\n",
      "114. Raspberry\n",
      "115. Redcurrant\n",
      "116. Salak\n",
      "117. Strawberry\n",
      "118. Strawberry Wedge\n",
      "119. Tamarillo\n",
      "120. Tangelo\n",
      "121. Tomato 1\n",
      "122. Tomato 2\n",
      "123. Tomato 3\n",
      "124. Tomato 4\n",
      "125. Tomato Cherry Red\n",
      "126. Tomato Heart\n",
      "127. Tomato Maroon\n",
      "128. Tomato Yellow\n",
      "129. Tomato not Ripened\n",
      "130. Walnut\n",
      "131. Watermelon\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Classes:\", len(class_names))\n",
    "for i, cls in enumerate(class_names):\n",
    "    print(f\"{i+1}. {cls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cda84913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresholding_segmentation(image):\n",
    "    ret2,th2=cv2.threshold(image,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    return ret2,th2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3eb500f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classes: ['Apple Braeburn', 'Apple Crimson Snow', 'Apple Golden 1', 'Apple Golden 2', 'Apple Golden 3', 'Apple Granny Smith', 'Apple Pink Lady', 'Apple Red 1', 'Apple Red 2', 'Apple Red 3', 'Apple Red Delicious', 'Apple Red Yellow 1', 'Apple Red Yellow 2', 'Apricot', 'Avocado', 'Avocado ripe', 'Banana', 'Banana Lady Finger', 'Banana Red', 'Beetroot', 'Blueberry']\n",
      "Number of classes: 21\n"
     ]
    }
   ],
   "source": [
    "class_names = selected_classes\n",
    "num_classes = len(class_names)\n",
    "print(f\"Selected classes: {class_names}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "913174c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = cv2.resize(image, (64, 64))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cd1459cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image):\n",
    "    if np.random.rand() > 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "    brightness_shift = np.random.randint(-30, 30)\n",
    "    image = np.clip(image.astype(np.int32) + brightness_shift, 0, 255).astype(np.uint8)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "08c4049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(root_path, class_names, selected_classes, is_training=False):\n",
    "    features, labels = [], []\n",
    "    class_to_idx = {cls: i for i, cls in enumerate(class_names)}\n",
    "\n",
    "    for class_name in selected_classes:\n",
    "        class_folder = os.path.join(root_path, class_name)\n",
    "\n",
    "        for file in tqdm(glob(os.path.join(class_folder, \"*.jpg\"))):\n",
    "            image = cv2.imread(file)\n",
    "            if image is None:\n",
    "                continue\n",
    "            if is_training:\n",
    "                image = augment_image(image)\n",
    "            image = preprocess_image(image)\n",
    "            features.append(image)\n",
    "            labels.append(class_to_idx[class_name])\n",
    "\n",
    "    \n",
    "    return np.array(features), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bfd0e52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 492/492 [00:00<00:00, 1269.96it/s]\n",
      "100%|██████████| 444/444 [00:00<00:00, 1564.43it/s]\n",
      "100%|██████████| 480/480 [00:00<00:00, 1389.12it/s]\n",
      "100%|██████████| 492/492 [00:00<00:00, 1348.01it/s]\n",
      "100%|██████████| 481/481 [00:00<00:00, 1819.19it/s]\n",
      "100%|██████████| 492/492 [00:00<00:00, 1546.41it/s]\n",
      "100%|██████████| 456/456 [00:00<00:00, 1711.55it/s]\n",
      "100%|██████████| 492/492 [00:00<00:00, 2297.42it/s]\n",
      "100%|██████████| 492/492 [00:00<00:00, 2154.09it/s]\n",
      "100%|██████████| 429/429 [00:00<00:00, 1839.52it/s]\n",
      "100%|██████████| 490/490 [00:00<00:00, 2122.69it/s]\n",
      "100%|██████████| 492/492 [00:00<00:00, 2238.00it/s]\n",
      "100%|██████████| 672/672 [00:00<00:00, 1982.57it/s]\n",
      "100%|██████████| 492/492 [00:00<00:00, 2180.47it/s]\n",
      "100%|██████████| 427/427 [00:00<00:00, 2479.97it/s]\n",
      "100%|██████████| 491/491 [00:00<00:00, 2142.14it/s]\n",
      "100%|██████████| 490/490 [00:00<00:00, 2669.35it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 2662.34it/s]\n",
      "100%|██████████| 490/490 [00:00<00:00, 2480.83it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 2494.84it/s]\n",
      "100%|██████████| 462/462 [00:00<00:00, 2575.03it/s]\n",
      "100%|██████████| 164/164 [00:00<00:00, 3266.82it/s]\n",
      "100%|██████████| 148/148 [00:00<00:00, 3299.27it/s]\n",
      "100%|██████████| 160/160 [00:00<00:00, 3074.14it/s]\n",
      "100%|██████████| 164/164 [00:00<00:00, 3310.72it/s]\n",
      "100%|██████████| 161/161 [00:00<00:00, 2969.63it/s]\n",
      "100%|██████████| 164/164 [00:00<00:00, 3334.10it/s]\n",
      "100%|██████████| 152/152 [00:00<00:00, 3283.86it/s]\n",
      "100%|██████████| 164/164 [00:00<00:00, 3132.57it/s]\n",
      "100%|██████████| 164/164 [00:00<00:00, 3213.44it/s]\n",
      "100%|██████████| 144/144 [00:00<00:00, 3017.70it/s]\n",
      "100%|██████████| 166/166 [00:00<00:00, 3368.01it/s]\n",
      "100%|██████████| 164/164 [00:00<00:00, 2891.04it/s]\n",
      "100%|██████████| 219/219 [00:00<00:00, 3482.74it/s]\n",
      "100%|██████████| 164/164 [00:00<00:00, 3210.94it/s]\n",
      "100%|██████████| 143/143 [00:00<00:00, 2253.82it/s]\n",
      "100%|██████████| 166/166 [00:00<00:00, 1755.63it/s]\n",
      "100%|██████████| 166/166 [00:00<00:00, 2215.36it/s]\n",
      "100%|██████████| 152/152 [00:00<00:00, 3423.50it/s]\n",
      "100%|██████████| 166/166 [00:00<00:00, 3061.48it/s]\n",
      "100%|██████████| 150/150 [00:00<00:00, 2735.40it/s]\n",
      "100%|██████████| 154/154 [00:00<00:00, 2881.87it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_dataset(train_dir, class_names, selected_classes, is_training=True)\n",
    "X_test, y_test = load_dataset(test_dir, class_names, selected_classes, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0ef19b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (8124, 64, 64, 3)\n",
      "Validation data shape: (2032, 64, 64, 3)\n",
      "Test data shape: (3395, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e981b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7732090a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 31, 31, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 14, 14, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 6, 6, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               1179904   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 21)                5397      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1278549 (4.88 MB)\n",
      "Trainable params: 1278549 (4.88 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "254/254 [==============================] - 14s 48ms/step - loss: 1.0525 - accuracy: 0.6446 - val_loss: 0.3824 - val_accuracy: 0.8607\n",
      "Epoch 2/10\n",
      "254/254 [==============================] - 12s 47ms/step - loss: 0.2668 - accuracy: 0.9029 - val_loss: 0.0728 - val_accuracy: 0.9754\n",
      "Epoch 3/10\n",
      "254/254 [==============================] - 13s 51ms/step - loss: 0.1475 - accuracy: 0.9474 - val_loss: 0.0267 - val_accuracy: 0.9936\n",
      "Epoch 4/10\n",
      "254/254 [==============================] - 12s 49ms/step - loss: 0.1071 - accuracy: 0.9639 - val_loss: 0.0346 - val_accuracy: 0.9867\n",
      "Epoch 5/10\n",
      "254/254 [==============================] - 12s 48ms/step - loss: 0.1085 - accuracy: 0.9627 - val_loss: 0.0658 - val_accuracy: 0.9754\n",
      "Epoch 6/10\n",
      "254/254 [==============================] - 12s 48ms/step - loss: 0.0959 - accuracy: 0.9684 - val_loss: 0.0281 - val_accuracy: 0.9902\n",
      "Epoch 7/10\n",
      "254/254 [==============================] - 12s 48ms/step - loss: 0.0629 - accuracy: 0.9797 - val_loss: 0.0193 - val_accuracy: 0.9931\n",
      "Epoch 8/10\n",
      "254/254 [==============================] - 12s 48ms/step - loss: 0.0628 - accuracy: 0.9778 - val_loss: 0.0091 - val_accuracy: 0.9961\n",
      "Epoch 9/10\n",
      "254/254 [==============================] - 12s 49ms/step - loss: 0.0601 - accuracy: 0.9785 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 10/10\n",
      "254/254 [==============================] - 12s 48ms/step - loss: 0.0457 - accuracy: 0.9846 - val_loss: 0.0100 - val_accuracy: 0.9966\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2728dfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 2s 14ms/step - loss: 0.1364 - accuracy: 0.9549\n",
      "Test Accuracy: 0.9549\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ef790e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "     Apple Braeburn       0.76      0.72      0.74       164\n",
      " Apple Crimson Snow       0.77      0.74      0.76       148\n",
      "     Apple Golden 1       0.97      0.71      0.82       160\n",
      "     Apple Golden 2       0.87      0.93      0.90       164\n",
      "     Apple Golden 3       0.83      1.00      0.91       161\n",
      " Apple Granny Smith       1.00      1.00      1.00       164\n",
      "    Apple Pink Lady       0.79      0.98      0.87       152\n",
      "        Apple Red 1       0.91      0.72      0.80       164\n",
      "        Apple Red 2       0.76      0.74      0.75       164\n",
      "        Apple Red 3       1.00      0.65      0.78       144\n",
      "Apple Red Delicious       0.97      1.00      0.99       166\n",
      " Apple Red Yellow 1       1.00      0.98      0.99       164\n",
      " Apple Red Yellow 2       1.00      1.00      1.00       219\n",
      "            Apricot       0.73      0.91      0.81       164\n",
      "            Avocado       1.00      0.97      0.99       143\n",
      "       Avocado ripe       0.96      1.00      0.98       166\n",
      "             Banana       0.75      0.74      0.74       166\n",
      " Banana Lady Finger       0.95      0.94      0.95       152\n",
      "         Banana Red       1.00      0.59      0.74       166\n",
      "           Beetroot       0.67      0.89      0.76       150\n",
      "          Blueberry       0.99      1.00      1.00       154\n",
      "\n",
      "          micro avg       0.88      0.87      0.87      3395\n",
      "          macro avg       0.89      0.87      0.87      3395\n",
      "       weighted avg       0.89      0.87      0.87      3395\n",
      "        samples avg       0.87      0.87      0.87      3395\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alaa Osman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Alaa Osman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_flat, y_train)\n",
    "y_pred = knn.predict(X_test_flat)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=selected_classes))\n",
    "\n",
    "model.save(\"fruits360_cnn_selected.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "584c723b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "36e14b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctk.set_appearance_mode(\"light\")\n",
    "ctk.set_default_color_theme(\"blue\")\n",
    "original_image = None\n",
    "image = None\n",
    "object_window = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "98b4a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_resize(img):\n",
    "    return cv2.resize(img, (256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "56bed348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_normalize(img):\n",
    "    return img / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7afb1b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_noise_reduction(img):\n",
    "    return cv2.GaussianBlur(img, (5, 5), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a9cdbeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_contrast_adjustment(img):\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "    merged = cv2.merge((cl, a, b))\n",
    "    return cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "29f75dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_color_conversion(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8acbd181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_augmentation_flip(img):\n",
    "    return cv2.flip(img, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "34eb2bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_augmentation_rotate(img):\n",
    "    M = cv2.getRotationMatrix2D((128, 128), 45, 1)\n",
    "    return cv2.warpAffine(img, M, (256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8b43aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_augmentation_bright(img):\n",
    "    return cv2.convertScaleAbs(img, alpha=1.2, beta=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "680919a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_thresholding(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "    return cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "524a1d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_blur(img):\n",
    "    return cv2.blur(img, (5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b4f7b985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_filtering(img):\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "    return cv2.filter2D(img, -1, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f20e1ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_morphology(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    opened = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n",
    "    return cv2.cvtColor(opened, cv2.COLOR_GRAY2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "34c87594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_eroded(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    eroded = cv2.erode(gray, kernel, iterations=1)\n",
    "    return cv2.cvtColor(eroded, cv2.COLOR_GRAY2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "831f37c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_dilated(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    dilated = cv2.dilate(gray, kernel, iterations=1)\n",
    "    return cv2.cvtColor(dilated, cv2.COLOR_GRAY2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fc02d837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_image(image):\n",
    "    try:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        ret2, segment_image = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        return segment_image, ret2\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Segmentation failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "62859ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sift_keypoints(image):\n",
    "    image_resized = cv2.resize(image, (256, 256))\n",
    "    gray = cv2.cvtColor(image_resized, cv2.COLOR_BGR2GRAY)\n",
    "    kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
    "    sharpened = cv2.filter2D(gray, -1, kernel)\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(sharpened, None)\n",
    "    img_keypoints = cv2.drawKeypoints(image_resized, keypoints, None,\n",
    "                                     flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    return img_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "af0d4bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image():\n",
    "    global image, original_image\n",
    "    \n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Image Files\", \"*.jpg *.jpeg *.png \")])\n",
    "    file_path = os.path.abspath(file_path)\n",
    "    original_image = cv2.imread(file_path)\n",
    "    image = original_image.copy()\n",
    "    display_image(image)\n",
    "\n",
    "def display_image(img):\n",
    "    global img_label, root\n",
    "    img = img.copy()\n",
    "    if img.max() <= 1.0:\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "    if len(img.shape) == 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_pil = Image.fromarray(img)\n",
    "    img_pil = img_pil.resize((500, 350), Image.Resampling.LANCZOS)\n",
    "    img_tk = ImageTk.PhotoImage(image=img_pil, master=root)\n",
    "    img_label.image = img_tk\n",
    "    img_label.configure(image=img_tk, text=\"\")\n",
    "    root.update_idletasks()\n",
    "    root.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3b4ef7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_image(img):\n",
    "    global img_label, root\n",
    "    \n",
    "    img = img.copy()\n",
    "    if img.max() <= 1.0:\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "    if len(img.shape) == 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_pil = Image.fromarray(img)\n",
    "    img_pil = img_pil.resize((500, 350), Image.Resampling.LANCZOS)\n",
    "    img_tk = ImageTk.PhotoImage(image=img_pil, master=root)\n",
    "    img_label.image = img_tk\n",
    "    img_label.configure(image=img_tk, text=\"\")\n",
    "    root.update_idletasks()\n",
    "    root.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "96a66703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_in_new_window(img, img_label):\n",
    "    global object_window\n",
    "    \n",
    "    img = img.copy()\n",
    "    if img.max() <= 1.0:\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "    if len(img.shape) == 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_pil = Image.fromarray(img)\n",
    "    img_pil = img_pil.resize((250, 150), Image.Resampling.LANCZOS)\n",
    "    img_tk = ImageTk.PhotoImage(image=img_pil, master=object_window)\n",
    "    img_label.image = img_tk\n",
    "    img_label.configure(image=img_tk, text=\"\")\n",
    "    object_window.update_idletasks()\n",
    "    object_window.update()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "30273888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(img):\n",
    "    global img_label, root\n",
    "    \n",
    "    img = img.copy()\n",
    "    if img.max() <= 1.0:\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "    if len(img.shape) == 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_pil = Image.fromarray(img)\n",
    "    img_pil = img_pil.resize((500, 350), Image.Resampling.LANCZOS)\n",
    "    img_tk = ImageTk.PhotoImage(image=img_pil, master=root)\n",
    "    img_label.image = img_tk\n",
    "    img_label.configure(image=img_tk, text=\"\")\n",
    "    root.update_idletasks()\n",
    "    root.update()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ebcc4df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_image_in_new_window(img, img_label):\n",
    "    global object_window\n",
    "    img = img.copy()\n",
    "    if img.max() <= 1.0:\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "    if len(img.shape) == 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_pil = Image.fromarray(img)\n",
    "    img_pil = img_pil.resize((600, 200), Image.Resampling.LANCZOS)\n",
    "    img_tk = ImageTk.PhotoImage(image=img_pil, master=object_window)\n",
    "    img_label.image = img_tk\n",
    "    img_label.configure(image=img_tk, text=\"\")\n",
    "    object_window.update_idletasks()\n",
    "    object_window.update()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "394cbf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_to_object():\n",
    "    global object_window, root\n",
    "    object_window = ctk.CTkToplevel(master=root)\n",
    "    object_window.title(\"🔍 Object Detection Window\")\n",
    "    object_window.geometry(\"1500x800\")\n",
    "    object_window.transient(root)\n",
    "    object_window.protocol(\"WM_DELETE_WINDOW\", lambda: on_object_window_close())\n",
    "\n",
    "    content_frame = ctk.CTkFrame(object_window, fg_color=\"#ffffff\")\n",
    "    content_frame.pack(pady=20, padx=20, fill=\"both\", expand=True)\n",
    "\n",
    "    title_label = ctk.CTkLabel(content_frame, text=\"Object Detection Processor\", font=(\"Roboto\", 16, \"bold\"))\n",
    "    title_label.pack(pady=10)\n",
    "\n",
    "    def load_new_image():\n",
    "        global object_window\n",
    "        \n",
    "        file_path = filedialog.askopenfilename(\n",
    "            filetypes=[(\"Image Files\", \"*.jpg *.jpeg *.png\")],\n",
    "            parent=object_window\n",
    "        )\n",
    "        \n",
    "        file_path = os.path.abspath(file_path)\n",
    "        new_image = cv2.imread(file_path)\n",
    "        error_label.configure(text=\"\")\n",
    "        display_image_in_new_window(new_image, input_img_label)\n",
    "        input_img_label.current_image = new_image\n",
    "        segmented_img_label.configure(image=None, text=\"Segmented Image\")\n",
    "        keypoints_img_label.configure(image=None, text=\"SIFT Keypoints\")\n",
    "        classified_img_label.configure(image=None, text=\"Detected Objects\")\n",
    "        object_window.lift()\n",
    "        object_window.focus_set()\n",
    "\n",
    "    browse_btn = ctk.CTkButton(content_frame, text=\"📁 Load Image\", font=(\"Roboto\", 14),\n",
    "                               command=load_new_image, fg_color=\"#3498db\", hover_color=\"#2980b9\",\n",
    "                               corner_radius=15, height=40)\n",
    "    browse_btn.pack(pady=10)\n",
    "\n",
    "    def detect_image():\n",
    "        if not hasattr(input_img_label, 'current_image') or input_img_label.current_image is None:\n",
    "            error_label.configure(text=\"No image loaded\")\n",
    "            return\n",
    "        error_label.configure(text=\"\")\n",
    "    \n",
    "        segmented_image, keypoints_image, image_with_boxes = process_image(input_img_label.current_image)\n",
    "        \n",
    "        display_image_in_new_window(segmented_image, segmented_img_label)\n",
    "        \n",
    "        display_image_in_new_window(keypoints_image, keypoints_img_label)\n",
    "        display_image_in_new_window(image_with_boxes, classified_img_label)\n",
    "        \n",
    "\n",
    "    detect_btn = ctk.CTkButton(content_frame, text=\"Detect\", font=(\"Roboto\", 14),\n",
    "                               command=detect_image, fg_color=\"#2ecc71\", hover_color=\"#27ae60\",\n",
    "                               corner_radius=15, height=40)\n",
    "    detect_btn.pack(pady=10)\n",
    "\n",
    "    error_label = ctk.CTkLabel(content_frame, text=\"\", font=(\"Roboto\", 12), text_color=\"red\")\n",
    "    error_label.pack(pady=5)\n",
    "\n",
    "    input_img_label = ctk.CTkLabel(content_frame, text=\"No image loaded\", font=(\"Roboto\", 12))\n",
    "    input_img_label.pack(pady=10)\n",
    "\n",
    "    output_frame = ctk.CTkFrame(content_frame, fg_color=\"transparent\")\n",
    "    output_frame.pack(pady=10, fill=\"both\", expand=True)\n",
    "\n",
    "    segmented_img_label = ctk.CTkLabel(output_frame, text=\"Segmented Image\", font=(\"Roboto\", 12))\n",
    "    segmented_img_label.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "    keypoints_img_label = ctk.CTkLabel(output_frame, text=\"SIFT Keypoints\", font=(\"Roboto\", 12))\n",
    "    keypoints_img_label.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "    classified_img_label = ctk.CTkLabel(output_frame, text=\"Detected Objects\", font=(\"Roboto\", 12))\n",
    "    classified_img_label.grid(row=1, column=0, columnspan=3, padx=10, pady=10, sticky=\"nsew\")\n",
    "\n",
    "\n",
    "    for i in range(3):\n",
    "        output_frame.grid_columnconfigure(i, weight=1)\n",
    "        output_frame.grid_rowconfigure(0, weight=1)\n",
    "        output_frame.grid_rowconfigure(1, weight=2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "72fd1b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_cnn(image):\n",
    "    image = cv2.resize(image, (64, 64))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "    return np.expand_dims(image, axis=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4173e13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_objects(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = gray / 255.0\n",
    "    gray_uint8 = (gray * 255).astype(np.uint8)\n",
    "\n",
    "    \n",
    "    _, binary_mask = cv2.threshold(gray_uint8, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "    \n",
    "    dist_transform = cv2.distanceTransform(binary_mask, cv2.DIST_L2, 5)\n",
    "    _, sure_fg = cv2.threshold(dist_transform, 0.4 * dist_transform.max(), 255, 0)\n",
    "    sure_fg = sure_fg.astype(np.uint8)\n",
    "\n",
    "    \n",
    "    sure_bg = cv2.dilate(binary_mask, kernel, iterations=3)\n",
    "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "\n",
    "    \n",
    "    _, markers = cv2.connectedComponents(sure_fg)\n",
    "    markers += 1\n",
    "    markers[unknown == 255] = 0\n",
    "    markers = markers.astype(np.int32)\n",
    "\n",
    "    \n",
    "    image_ws = image.copy()\n",
    "    markers = cv2.watershed(image_ws, markers)\n",
    "    object_mask = np.uint8(markers > 1)\n",
    "\n",
    "    \n",
    "    contours, _ = cv2.findContours(object_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    predicted_classes = []\n",
    "\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        area = cv2.contourArea(cnt)\n",
    "\n",
    "       \n",
    "        if area < 1000:\n",
    "            continue\n",
    "\n",
    "        fruit_crop = image[y:y+h, x:x+w]\n",
    "        input_tensor = preprocess_for_cnn(fruit_crop)\n",
    "\n",
    "        pred_probs = model.predict(input_tensor, verbose=0)\n",
    "        pred_index = np.argmax(pred_probs)\n",
    "        pred_class = selected_classes[pred_index]\n",
    "        predicted_classes.append(pred_class)\n",
    "    return predicted_classes, contours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "64fdc4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes_and_labels(original_image):\n",
    "    image = original_image.copy() \n",
    "   \n",
    "    predicted_classes, contours = classify_objects(original_image)\n",
    "    for idx, cnt in enumerate(contours):\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    \n",
    "        if w < 30 or h < 30:\n",
    "            continue\n",
    "\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)  \n",
    "\n",
    "\n",
    "        label = predicted_classes[idx]\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(image, label, (x, y - 10), font, 0.7, (0, 0, 0), 2)  \n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "01310909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_task(task_name, _=None):\n",
    "    global original_image, image\n",
    "    task_map = {\n",
    "        \"Image Resizing\": on_resize,\n",
    "        \"Normalization\": on_normalize,\n",
    "        \"Noise Reduction\": on_noise_reduction,\n",
    "        \"Contrast Adjustment\": on_contrast_adjustment,\n",
    "        \"Color Space Conversion\": on_color_conversion,\n",
    "        \"Flipping\": on_augmentation_flip,\n",
    "        \"Rotation\": on_augmentation_rotate,\n",
    "        \"Brightness\": on_augmentation_bright,\n",
    "        \"Thresholding\": on_thresholding,\n",
    "        \"Blurring\": on_blur,\n",
    "        \"Sharpening\": on_filtering,\n",
    "        \"Dilation\": on_dilated,\n",
    "        \"Erosion\": on_eroded,\n",
    "        \"Morphological Operations\": on_morphology,\n",
    "        \"SIFT\": extract_sift_features,\n",
    "        \"GO\": go_to_object,\n",
    "    }\n",
    "    task_function = task_map.get(task_name)\n",
    "    if task_function:\n",
    "        if task_name == \"GO\":\n",
    "            task_function()\n",
    "        else:\n",
    "            processed = task_function(original_image.copy())\n",
    "            image = processed\n",
    "            display_image(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ac216bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_image(image):\n",
    "    segmented_image, _ = segment_image(image)\n",
    "    keypoints_image = extract_sift_keypoints(image)\n",
    "    \n",
    "    image_with_boxes = draw_boxes_and_labels(image)\n",
    "\n",
    "    return segmented_image, keypoints_image, image_with_boxes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "40a98a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alaa Osman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\customtkinter\\windows\\widgets\\core_widget_classes\\ctk_base_class.py:179: UserWarning: CTkLabel Warning: Given image is not CTkImage but <class 'PIL.ImageTk.PhotoImage'>. Image can not be scaled on HighDPI displays, use CTkImage instead.\n",
      "\n",
      "  warnings.warn(f\"{type(self).__name__} Warning: Given image is not CTkImage but {type(image)}. Image can not be scaled on HighDPI displays, use CTkImage instead.\\n\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 46\u001b[0m\n\u001b[0;32m     40\u001b[0m go_btn \u001b[38;5;241m=\u001b[39m ctk\u001b[38;5;241m.\u001b[39mCTkButton(main_frame, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m➡ Go to Object Detection Page\u001b[39m\u001b[38;5;124m\"\u001b[39m, font\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRoboto\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m18\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     41\u001b[0m                        fg_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#ff6200\u001b[39m\u001b[38;5;124m\"\u001b[39m, hover_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#cc4e00\u001b[39m\u001b[38;5;124m\"\u001b[39m, corner_radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     42\u001b[0m                        height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, command\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m: handle_task(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGO\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     43\u001b[0m                        border_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, border_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#ffffff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m go_btn\u001b[38;5;241m.\u001b[39mpack(pady\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m \u001b[43mroot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alaa Osman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\customtkinter\\windows\\ctk_tk.py:165\u001b[0m, in \u001b[0;36mCTk.mainloop\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeiconify()\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_window_exists \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 165\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mmainloop(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alaa Osman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tkinter\\__init__.py:1458\u001b[0m, in \u001b[0;36mMisc.mainloop\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmainloop\u001b[39m(\u001b[38;5;28mself\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m   1457\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1458\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "get_ipython().run_line_magic('gui', 'tk')\n",
    "\n",
    "root = ctk.CTk()\n",
    "root.title(\"🧠 Smart Image Processor\")\n",
    "root.geometry(\"1500x800\")\n",
    "\n",
    "main_frame = ctk.CTkFrame(root, corner_radius=10, fg_color=\"#ffffff\")\n",
    "main_frame.place(relx=0.5, rely=0.5, anchor=\"center\", relwidth=0.9, relheight=0.9)\n",
    "\n",
    "global img_label\n",
    "img_label = ctk.CTkLabel(main_frame, text=\"No image loaded\", corner_radius=8, fg_color=\"#f1f3f5\")\n",
    "img_label.pack(pady=15)\n",
    "img_label.update_idletasks()\n",
    "img_label.update()\n",
    "\n",
    "browse_btn = ctk.CTkButton(main_frame, text=\"📁 Choose Image\", font=(\"Roboto\", 14, \"bold\"),\n",
    "                           command=load_image, fg_color=\"#3498db\", hover_color=\"#2980b9\",\n",
    "                           corner_radius=15, height=40)\n",
    "browse_btn.pack(pady=15)\n",
    "\n",
    "buttons_frame = ctk.CTkFrame(main_frame, fg_color=\"transparent\")\n",
    "buttons_frame.pack(pady=20)\n",
    "\n",
    "tasks = [\n",
    "    \"Image Resizing\", \"Normalization\", \"Noise Reduction\",\n",
    "    \"Contrast Adjustment\", \"Color Space Conversion\", \"Flipping\", \"Rotation\", \"Brightness\",\n",
    "    \"Thresholding\", \"Blurring\", \"Sharpening\", \"Dilation\", \"Erosion\",\n",
    "    \"Morphological Operations\", \"SIFT\"\n",
    "]\n",
    "\n",
    "for idx, task in enumerate(tasks):\n",
    "    btn = ctk.CTkButton(buttons_frame, text=task, font=(\"Roboto\", 12, \"bold\"),\n",
    "                        fg_color=\"#2ecc71\", hover_color=\"#27ae60\", corner_radius=15,\n",
    "                        height=40, command=lambda t=task: handle_task(t))\n",
    "    btn.grid(row=idx // 5, column=idx % 5, padx=10, pady=10, sticky=\"ew\")\n",
    "\n",
    "for i in range(5):\n",
    "    buttons_frame.grid_columnconfigure(i, weight=1)\n",
    "\n",
    "go_btn = ctk.CTkButton(main_frame, text=\"➡ Go to Object Detection Page\", font=(\"Roboto\", 18, \"bold\"),\n",
    "                       fg_color=\"#ff6200\", hover_color=\"#cc4e00\", corner_radius=20,\n",
    "                       height=50, width=200, command=lambda: handle_task(\"GO\"),\n",
    "                       border_width=2, border_color=\"#ffffff\")\n",
    "go_btn.pack(pady=20)\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
